import twitter
import json
import pandas as pd
import base64

# Variables that contains the user credentials to access Twitter API
ACCESS_TOKEN = ' '
ACCESS_SECRET = ' '
CONSUMER_KEY = ' '
CONSUMER_SECRET = ' '

# Initiate the connection to Twitter Streaming API
#twitter_stream = TwitterStream(auth=oauth)
api = twitter.Api(consumer_key=CONSUMER_KEY,
                  consumer_secret=CONSUMER_SECRET,
                  access_token_key=ACCESS_TOKEN,
                  access_token_secret=ACCESS_SECRET)
                  
import re
from textblob import TextBlob

def clean_tweet(tweet):
    '''
    Utility function to clean tweet text by removing links, special characters
    using simple regex statements.
    '''
    return ' '.join(re.sub("(@[A-Za-z0-9]+)|([^0-9A-Za-z \t]) |(\w+:\/\/\S+)", " ", tweet).split())

def get_tweet_sentiment(tweet):
    '''
    Utility function to classify sentiment of passed tweet
    using textblob's sentiment method
    '''
    # create TextBlob object of passed tweet text
    analysis = TextBlob(clean_tweet(tweet))
    # set sentiment
    if analysis.sentiment.polarity > 0:
        return 'positive'
    elif analysis.sentiment.polarity == 0:
        return 'neutral'
    else:
        return 'negative'
    
def get_min_max(tweets):
    ids = []
    for tweet in tweets:
        # print tweet
        if type(tweet) is list:
            tweet = tweet[0]
        ids.append(tweet.id)
    min_id = min(ids)
    max_id = max(ids)
    return min_id, max_id
    
def get_tweets(term, count):
    all_tweets = []
    max_id = 843567375765159939000000
    #print max_id
    loop_count = count / 100
    for i in range(loop_count):
        tweets = api.GetSearch(term=term, count = 100)
        #print 'Total number of tweets found - '  +  str(len(tweets))
        try:
            min_id, max_id = get_min_max(tweets)
            all_tweets = all_tweets + tweets
        except:
            print 'something wrong'
            pass
    return all_tweets
  

def get_tweets_df(tweets):
    result = []
    for tweet in tweets:
        favorite_count = tweet.favorite_count
        retweet_count = tweet.retweet_count
        source = tweet.source
        text = tweet.text
        urls = tweet.urls
        sentiment = get_tweet_sentiment(text)
        
        result.append({
            #'text': base64.b64encode(text.encode('ascii', 'ignore').decode('ascii')),
            'text': text.encode('ascii', 'ignore').decode('ascii'),
            'sentiment': sentiment,
            'favorite_count' : favorite_count,
            'source' : source,
            'retweet_count' : retweet_count,
            'user_fav_count': tweet.user.favourites_count,
            'user_follower_count': tweet.user.followers_count,
            'user_friends_count': tweet.user.friends_count,
            'user_screen_name' : tweet.user.screen_name.encode('ascii', 'ignore').decode('ascii'),
            'user_name': tweet.user.name.encode('ascii', 'ignore').decode('ascii'),
            'user_url': tweet.user.url
        })
    result_df = pd.DataFrame(result)
    return result_df

def print_tweet(tweet):
    print '---- Printing tweet ----'
    print tweet.favorite_count
    print tweet.text
    print ' --------- x --------- '  
    
print 'Fetching tweets for Politician X'
tweets_X = get_tweets('Politician X', 500)
print 'Total number of tweets fetched = ' + str(len(tweets_yogi))

print 'Fetching tweets for Politician Y'
tweets_Y = get_tweets('Politician Y', 500)
print 'Total number of tweets fetched = ' + str(len(tweets_Y))

print 'Fetching tweets for Politician Z'
tweets_Z = get_tweets('Politician Y', 500)
print 'Total number of tweets fetched = ' + str(len(tweets_Z))

df_yogi = get_tweets_df(tweets_X)
df_namo = get_tweets_df(tweets_Y)
df_ak = get_tweets_df(tweets_Z)

df_yogi.to_csv('X.csv')
df_namo.to_csv('Y.csv')
df_ak.to_csv('Z.csv')
